# Kafka åˆ†å¸ƒå¼æ¶ˆè´¹è¯´æ˜

## é—®é¢˜ï¼šå¤šä¸ªæœåŠ¡å‰¯æœ¬ä¼šé‡å¤æ¶ˆè´¹å—?

**ç­”æ¡ˆï¼šä¸ä¼šï¼** åªè¦é…ç½®æ­£ç¡®ï¼Œä½¿ç”¨ç›¸åŒçš„ Consumer Group IDï¼Œå¤šä¸ªæœåŠ¡å‰¯æœ¬ä¸ä¼šé‡å¤æ¶ˆè´¹åŒä¸€æ¡æ¶ˆæ¯ã€‚

## å·¥ä½œåŸç†

### 1. Consumer Group æœºåˆ¶

Kafka ä½¿ç”¨ **Consumer Group** æ¥ç®¡ç†æ¶ˆè´¹è€…é›†ç¾¤ï¼š

```yaml
# etc/hellogozero.yaml
Kafka:
  Group: hello-gozero-group  # æ‰€æœ‰å‰¯æœ¬ä½¿ç”¨ç›¸åŒçš„ Group ID
```

- **åŒä¸€ä¸ª Consumer Group å†…**ï¼šæ¯æ¡æ¶ˆæ¯åªä¼šè¢«ä¸€ä¸ªæ¶ˆè´¹è€…å¤„ç†
- **ä¸åŒ Consumer Group**ï¼šæ¯ä¸ª Group ç‹¬ç«‹æ¶ˆè´¹ï¼Œå¯ä»¥é‡å¤æ¶ˆè´¹

### 2. åˆ†åŒºåˆ†é…ç­–ç•¥

```
Topic: hello-gozero-topic (å‡è®¾æœ‰ 3 ä¸ªåˆ†åŒº)

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Partition 0 â”‚  Partition 1 â”‚  Partition 2 â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚             â”‚             â”‚
â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Consumer 1 â”‚  Consumer 2 â”‚  Consumer 3  â”‚
â”‚  (Pod 1)    â”‚  (Pod 2)    â”‚  (Pod 3)     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       åŒä¸€ä¸ª Consumer Group
```

æ¯ä¸ªåˆ†åŒºåªä¼šåˆ†é…ç»™ç»„å†…çš„ä¸€ä¸ªæ¶ˆè´¹è€…ã€‚

### 3. Rebalance æœºåˆ¶

å½“æ¶ˆè´¹è€…æ•°é‡å˜åŒ–æ—¶ï¼ˆPod æ‰©ç¼©å®¹ï¼‰ï¼ŒKafka ä¼šè‡ªåŠ¨è§¦å‘ **Rebalance**ï¼š

```
åœºæ™¯ 1: æ–°å¢å‰¯æœ¬
Consumer 1: [Partition 0, 1, 2]  â†’  Consumer 1: [Partition 0, 1]
                                     Consumer 2: [Partition 2]

åœºæ™¯ 2: å‰¯æœ¬ä¸‹çº¿
Consumer 1: [Partition 0]  â†’  Consumer 2: [Partition 0, 1, 2]
Consumer 2: [Partition 1]
Consumer 3: [Partition 2]  (ä¸‹çº¿)
```

## å½“å‰é…ç½®åˆ†æ

### âœ… æ­£ç¡®çš„é…ç½®

```go
// infra/queue/kafka.go
reader := kafka.NewReader(kafka.ReaderConfig{
    Brokers:        conf.Brokers,
    Topic:          conf.Topic,
    GroupID:        conf.Group,          // âœ… ä½¿ç”¨ Consumer Group
    CommitInterval: time.Second,         // âœ… è‡ªåŠ¨æäº¤ offset
    StartOffset:    kafka.LastOffset,    // âœ… æ–°æ¶ˆè´¹è€…ä»æœ€æ–°æ¶ˆæ¯å¼€å§‹
})
```

è¿™ä¸ªé…ç½®ç¡®ä¿ï¼š

1. å¤šä¸ªå‰¯æœ¬è‡ªåŠ¨åè°ƒåˆ†åŒºåˆ†é…
2. Offset å®šæœŸæäº¤åˆ° Kafka
3. æ–°å¯åŠ¨çš„æ¶ˆè´¹è€…ä¸ä¼šå¤„ç†å†å²æ¶ˆæ¯

## ä»éœ€æ³¨æ„çš„é—®é¢˜

### âš ï¸ æç«¯æƒ…å†µä¸‹å¯èƒ½é‡å¤æ¶ˆè´¹

è™½ç„¶ä½¿ç”¨äº† Consumer Groupï¼Œä½†åœ¨ä»¥ä¸‹æƒ…å†µä»å¯èƒ½é‡å¤æ¶ˆè´¹ï¼š

#### 1. Rebalance æœŸé—´

```
æ—¶é—´çº¿:
T1: Consumer 1 è¯»å– Message A
T2: Consumer 1 å¤„ç† Message A
T3: Rebalance è§¦å‘ (æ–° Pod åŠ å…¥)
T4: Consumer 1 å°è¯•æäº¤ offset - å¤±è´¥ (å·²å¤±å»åˆ†åŒºæ‰€æœ‰æƒ)
T5: Consumer 2 æ¥ç®¡åˆ†åŒºï¼Œä»ä¸Šæ¬¡æäº¤çš„ offset å¼€å§‹
T6: Consumer 2 é‡æ–°è¯»å– Message A â† é‡å¤æ¶ˆè´¹
```

#### 2. å¤„ç†æˆåŠŸä½†æäº¤å¤±è´¥

```go
// kafka_consumer.go
if err := w.processMessage(ctx, message); err != nil {
    // å¤„ç†æˆåŠŸ
}

// æäº¤ offset
if err := w.reader.CommitMessages(ctx, message); err != nil {
    // æäº¤å¤±è´¥! â† ä¸‹æ¬¡é‡å¯ä¼šé‡æ–°æ¶ˆè´¹
    w.logger.Errorf("Failed to commit message: %v", err)
}
```

#### 3. æ¶ˆè´¹è€…å´©æºƒ

```
Consumer 1 æ­£åœ¨å¤„ç†æ¶ˆæ¯ â†’ è¿›ç¨‹å´©æºƒ
â†“
Consumer 2 æ¥ç®¡åˆ†åŒº â†’ ä»ä¸Šæ¬¡æäº¤çš„ offset å¼€å§‹
â†“
é‡æ–°å¤„ç†æœªæäº¤çš„æ¶ˆæ¯
```

### âœ… è§£å†³æ–¹æ¡ˆï¼šå¹‚ç­‰æ€§è®¾è®¡

**æ‰€æœ‰æ¶ˆæ¯å¤„ç†å¿…é¡»è®¾è®¡ä¸ºå¹‚ç­‰æ“ä½œ**ï¼Œå³ï¼šé‡å¤æ‰§è¡Œäº§ç”Ÿç›¸åŒç»“æœã€‚

#### æ–¹æ¡ˆä¸€ï¼šæ•°æ®åº“å”¯ä¸€é”®çº¦æŸ

```go
// ä½¿ç”¨ user_id + event_type + timestamp ä½œä¸ºå”¯ä¸€é”®
func (h *UserEventHandler) handleUserRegistered(ctx context.Context, event UserEvent) error {
    // ä½¿ç”¨ INSERT IGNORE æˆ– ON DUPLICATE KEY UPDATE
    query := `
        INSERT IGNORE INTO user_events (user_id, event_type, timestamp, processed)
        VALUES (?, ?, ?, 1)
    `
    _, err := h.db.ExecContext(ctx, query, event.UserID, event.EventType, event.Timestamp)
    if err != nil {
        return err
    }
    
    // å¦‚æœæ’å…¥æˆåŠŸ (RowsAffected = 1)ï¼Œæ‰§è¡Œä¸šåŠ¡é€»è¾‘
    // å¦‚æœæ’å…¥å¤±è´¥ (é‡å¤é”®)ï¼Œè¯´æ˜å·²å¤„ç†ï¼Œç›´æ¥è¿”å›
    return nil
}
```

#### æ–¹æ¡ˆäºŒï¼šæ¶ˆæ¯å»é‡è¡¨

```sql
-- åˆ›å»ºæ¶ˆæ¯å»é‡è¡¨
CREATE TABLE message_dedup (
    id BIGINT AUTO_INCREMENT PRIMARY KEY,
    message_key VARCHAR(255) NOT NULL,      -- Kafka message key
    partition_id INT NOT NULL,
    offset_id BIGINT NOT NULL,
    processed_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    UNIQUE KEY uk_partition_offset (partition_id, offset_id),
    KEY idx_message_key (message_key)
);
```

```go
func (h *UserEventHandler) Handle(ctx context.Context, message kafka.Message) error {
    // 1. å…ˆå°è¯•æ’å…¥å»é‡è®°å½•
    query := `
        INSERT INTO message_dedup (message_key, partition_id, offset_id)
        VALUES (?, ?, ?)
    `
    _, err := h.db.ExecContext(ctx, query, 
        string(message.Key), 
        message.Partition, 
        message.Offset,
    )
    
    // å¦‚æœæ’å…¥å¤±è´¥ (é‡å¤é”®)ï¼Œè¯´æ˜å·²å¤„ç†è¿‡
    if err != nil && isDuplicateKeyError(err) {
        h.logger.Infof("Message already processed, skipping")
        return nil
    }
    
    if err != nil {
        return fmt.Errorf("failed to insert dedup record: %w", err)
    }
    
    // 2. å¤„ç†ä¸šåŠ¡é€»è¾‘
    return h.processBusinessLogic(ctx, message)
}
```

#### æ–¹æ¡ˆä¸‰ï¼šåˆ†å¸ƒå¼é” + çŠ¶æ€æ£€æŸ¥

```go
func (h *UserEventHandler) handleUserRegistered(ctx context.Context, event UserEvent) error {
    lockKey := fmt.Sprintf("user:register:%s", event.UserID)
    
    // 1. è·å–åˆ†å¸ƒå¼é”
    lock, err := h.redis.ObtainLock(ctx, lockKey, 30*time.Second)
    if err != nil {
        return err
    }
    defer lock.Release(ctx)
    
    // 2. æ£€æŸ¥æ˜¯å¦å·²å¤„ç†
    processed, err := h.checkEventProcessed(ctx, event.UserID, event.Timestamp)
    if err != nil {
        return err
    }
    if processed {
        h.logger.Infof("Event already processed")
        return nil
    }
    
    // 3. ä½¿ç”¨äº‹åŠ¡å¤„ç†ä¸šåŠ¡ + æ ‡è®°å·²å¤„ç†
    return h.processWithTransaction(ctx, event)
}
```

## æ€§èƒ½ä¼˜åŒ–å»ºè®®

### 1. åˆç†è®¾ç½®åˆ†åŒºæ•°

```bash
# Topic åˆ†åŒºæ•°åº”è¯¥ >= æœåŠ¡å‰¯æœ¬æ•°
# ä¾‹å¦‚ï¼š3 ä¸ª Podï¼Œè‡³å°‘éœ€è¦ 3 ä¸ªåˆ†åŒº

kafka-topics.sh --create \
  --topic hello-gozero-topic \
  --partitions 6 \              # å»ºè®® 2x æœåŠ¡å‰¯æœ¬æ•°
  --replication-factor 3 \
  --bootstrap-server kafka:9092
```

**åŸå› ï¼š**

- åˆ†åŒºæ•° < å‰¯æœ¬æ•°ï¼šéƒ¨åˆ†æ¶ˆè´¹è€…ç©ºé—²
- åˆ†åŒºæ•° = å‰¯æœ¬æ•°ï¼šå®Œç¾å¹³è¡¡
- åˆ†åŒºæ•° > å‰¯æœ¬æ•°ï¼šæ›´å¥½çš„æ‰©å±•æ€§

### 2. è°ƒæ•´æäº¤é—´éš”

```go
// å½“å‰é…ç½®
CommitInterval: time.Second,  // æ¯ç§’æäº¤

// ä½å»¶è¿Ÿåœºæ™¯ï¼ˆå‡å°‘é‡å¤æ¶ˆè´¹é£é™©ï¼‰
CommitInterval: 100 * time.Millisecond,

// é«˜åååœºæ™¯ï¼ˆå‡å°‘æäº¤å¼€é”€ï¼‰
CommitInterval: 5 * time.Second,
```

### 3. æ‰‹åŠ¨æäº¤ vs è‡ªåŠ¨æäº¤

```go
// å½“å‰ï¼šè‡ªåŠ¨æäº¤ (å¤„ç†å®Œç«‹å³æäº¤)
if err := w.reader.CommitMessages(ctx, message); err != nil {
    w.logger.Errorf("Failed to commit: %v", err)
}

// ä¼˜åŒ–ï¼šæ‰¹é‡æäº¤ (å¤„ç† N æ¡åæäº¤)
var messages []kafka.Message
for i := 0; i < batchSize; i++ {
    msg, _ := reader.FetchMessage(ctx)
    processMessage(msg)
    messages = append(messages, msg)
}
reader.CommitMessages(ctx, messages...)
```

## ç›‘æ§æŒ‡æ ‡

å»ºè®®ç›‘æ§ä»¥ä¸‹æŒ‡æ ‡ä»¥æ£€æµ‹é‡å¤æ¶ˆè´¹ï¼š

```go
// 1. æ¶ˆè´¹å»¶è¿Ÿ (Lag)
SELECT 
    partition_id,
    current_offset,
    log_end_offset,
    (log_end_offset - current_offset) AS lag
FROM kafka_consumer_offsets
WHERE group_id = 'hello-gozero-group';

// 2. æ¶ˆæ¯å¤„ç†é€Ÿç‡
messages_processed_total{status="success"}
messages_processed_total{status="duplicate"}

// 3. Rebalance é¢‘ç‡
consumer_rebalance_total{group="hello-gozero-group"}
```

## æµ‹è¯•éªŒè¯

### 1. æ­£å¸¸æ¶ˆè´¹æµ‹è¯•

```bash
# å¯åŠ¨ 3 ä¸ªæœåŠ¡å‰¯æœ¬
docker-compose up --scale app=3

# å‘é€æµ‹è¯•æ¶ˆæ¯
python debug/user/register_user.py

# æ£€æŸ¥æ—¥å¿—ï¼šæ¯æ¡æ¶ˆæ¯åªè¢«å¤„ç†ä¸€æ¬¡
docker-compose logs app | grep "Processing user event"
```

### 2. Rebalance æµ‹è¯•

```bash
# å¯åŠ¨ 2 ä¸ªå‰¯æœ¬
docker-compose up --scale app=2

# å‘é€æ¶ˆæ¯ï¼ˆæŒç»­å‘é€ï¼‰
while true; do
    python debug/user/register_user.py
    sleep 0.5
done

# åœ¨å¦ä¸€ä¸ªç»ˆç«¯æ‰©å®¹åˆ° 3 ä¸ªå‰¯æœ¬
docker-compose up --scale app=3 --no-recreate

# è§‚å¯Ÿæ—¥å¿—ï¼šåº”è¯¥çœ‹åˆ° Rebalance ä½†æ²¡æœ‰é‡å¤å¤„ç†
```

### 3. å´©æºƒæ¢å¤æµ‹è¯•

```bash
# å¯åŠ¨æœåŠ¡
docker-compose up app

# å‘é€æ¶ˆæ¯
python debug/user/register_user.py

# åœ¨æ¶ˆæ¯å¤„ç†æœŸé—´å¼ºåˆ¶åœæ­¢
docker-compose kill app

# é‡æ–°å¯åŠ¨
docker-compose up app

# æ£€æŸ¥ï¼šæ¶ˆæ¯åº”è¯¥è¢«é‡æ–°å¤„ç† (å¹‚ç­‰æ€§ä¿è¯å®‰å…¨)
```

## æ€»ç»“

### âœ… å½“å‰é…ç½®æ˜¯æ­£ç¡®çš„

æ‚¨çš„ç³»ç»Ÿé…ç½®äº†æ­£ç¡®çš„ Consumer Group æœºåˆ¶ï¼Œ**ä¸ä¼šåœ¨æ­£å¸¸æƒ…å†µä¸‹é‡å¤æ¶ˆè´¹**ã€‚

### âš ï¸ ä½†éœ€è¦å®ç°å¹‚ç­‰æ€§

ç”±äº Rebalanceã€ç½‘ç»œæ•…éšœç­‰æç«¯æƒ…å†µï¼Œä»å¯èƒ½é‡å¤æ¶ˆè´¹ï¼Œå› æ­¤ï¼š

1. **å¿…é¡»å®ç°ä¸šåŠ¡å¹‚ç­‰æ€§**
2. **ä½¿ç”¨æ•°æ®åº“å”¯ä¸€çº¦æŸ**
3. **è€ƒè™‘åˆ†å¸ƒå¼é”**
4. **è®°å½•æ¶ˆæ¯å¤„ç†çŠ¶æ€**

### ğŸ“Š æ¨èçš„å®Œæ•´æ–¹æ¡ˆ

```go
func (h *UserEventHandler) Handle(ctx context.Context, message kafka.Message) error {
    // 1. å»é‡æ£€æŸ¥ (åŸºäº offset)
    if isDuplicate := h.checkDuplicate(message); isDuplicate {
        return nil
    }
    
    // 2. ä¸šåŠ¡å¤„ç† (å¹‚ç­‰è®¾è®¡)
    if err := h.processIdempotent(ctx, message); err != nil {
        return err
    }
    
    // 3. æ ‡è®°å·²å¤„ç† (ä¸ä¸šåŠ¡åœ¨åŒä¸€äº‹åŠ¡ä¸­)
    return h.markProcessed(message)
}
```

### å‚è€ƒèµ„æ–™

- [Kafka Consumer Groups](https://kafka.apache.org/documentation/#intro_consumers)
- [Delivery Semantics](https://kafka.apache.org/documentation/#semantics)
- [Rebalance Protocol](https://kafka.apache.org/documentation/#consumerconfigs)
